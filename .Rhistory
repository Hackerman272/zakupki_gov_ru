'contractInputNameContractNumber',
'publishDateFrom',
'publishDateTo',
'updateDateFrom',
'updateDateTo')
## имя браузера для маскировки запроса по getURL()
userAgent <- 'Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko'
## имя файла для экспорта
exportCsvFileName <- paste0('zakupki_gov_ru_', Sys.time(), '.csv')
# ФУНКЦИИ ----------------------------------------------------------------------
#
#
# Применить xpath запрос и почистить возвращаемый результат
#  от хвостовых пробелов и спецсимволов
#
xpathApplyAndClean <- function(root.node, xpath.text, return.mode = 'value',
attr.name = NULL) {
# сами теги
if (return.mode == 'value') {
result <- xpathSApply(root.node, xpath.text, xmlValue)
}
if (return.mode == 'attr') {
result <- xpathSApply(root.node, xpath.text, xmlGetAttr, attr.name)
}
# убираем перевод каретки
result <- gsub(result, pattern = '\r\n', replacement = '')
# убираем пробелы по краям
result <- gsub(result, pattern = "^\\s+|\\s+$", replacement = '')
# возвращаем значения
return(result)
}
#
#
# Вместо try-catch для результатов xpath запроса:
#  если результат возвращается нулевой, меняем его на NA
tryXpath <- function(xpath.result) {
if (length(xpath.result) == 0) {
xpath.result <- NA
}
return(xpath.result)
}
# ПЕРЕМЕННЫЕ -------------------------------------------------------------------
#
## переменная часть запроса данных (URL)
var.html <- c('',                                       # searchString
'on',                                     # morphology
'1',                                      # pageNumber
'false',                                  # sortDirection
'_50',                                    # recordsPerPage
'PO_DATE_OBNOVLENIJA',                    # sortBy
'on',                                     # fz44
'0',                                      # priceFrom
'1000000',                                # priceTo
'',                                       # budgetLevels
'',                                       # budgetName
'',                                       # nonBudgetCodesList
'on',                                     # placingWayForContractList_4
'4',                                      # placingWayForContractList
'on',                                     # contractStageList_1
'on',                                     # contractStageList_2
'1%2C2',                                  # contractStageList
'',                                       # regions
'',                                       # contractDateFrom
'',                                       # contractDateTo
'',                                       # contractInputNameDefenseOrderNumber
'',                                       # contractInputNameContractNumber
'01.06.2017',                             # publishDateFrom
'31.08.2017',                             # publishDateTo
'',                                       # updateDateFrom
''                                        # updateDateTo
)
fileURL <- paste0(paste0(const.html, '=', var.html), collapse = '&')
# ЗАГРУЗКА ---------------------------------------------------------------------
#
## загружаем текст html-страницы
html <- getURL(fileURL, .encoding = 'UTF-8',
ssl.verifypeer = FALSE,
.opts = list(useragent = userAgent,
followlocation = TRUE))
## разбираем как html
doc <- htmlTreeParse(html, useInternalNodes = T)
## корневой элемент
rootNode <- xmlRoot(doc)
# ПАРСИНГ ----------------------------------------------------------------------
#
# РЕЕСТР КОНТРАКТОВ ============================================================
#
## настроечные переменные
#...............................................................................
### сколько страниц в выдаче
n.pages <- as.numeric(xpathApplyAndClean(rootNode,
"//div[@class = 'paginator greyBox']/ul/li"))
n.pages <- n.pages[!is.na(n.pages)]
n.pages
rootNode
fileURL
#
# В этом скрипте содержится код разбора выдачи сайта госзакупок zakupki.gov.ru
# Начало работы: 29.08.2017
# Автор: Светлана Аксюк (s.a.aksuk@gmail.com)
#
# Данные загружаются по запросу через URL.
# Пример URL для разбора:
# http://zakupki.gov.ru/epz/contract/quicksearch/search.html?searchString=&morphology=on&pageNumber=1&sortDirection=false&recordsPerPage=_50&sortBy=PO_DATE_OBNOVLENIJA&priceFrom=0&priceTo=1000000&budgetLevels=&budgetName=&nonBudgetCodesList=&placingWayForContractList_4=on&placingWayForContractList=4&contractStageList_1=on&contractStageList_2=on&contractStageList=1%2C2&regions=&contractDateFrom=&contractDateTo=&contractInputNameDefenseOrderNumber=&contractInputNameContractNumber=&publishDateFrom=01.01.2016&publishDateTo=29.08.2017&updateDateFrom=&updateDateTo=
#
# Результаты -- характеристики госзакупок из базы данных -- записыввются
#  в .csv файл.
# Ограничение API: 500 записей при выгрузке вручную с сайта.
# Мы запрашиваем все записи с максимальным количеством на странице: 50,
#  потом листаем в цикле. Внимание: заказы быстро добавляются, в конце
#  стоит проверить таблицу на наличие дубликатов. Уникальный идентификатор --
#  номер заказа (ContractID).
#
# ПАКЕТЫ -----------------------------------------------------------------------
#
library('RCurl')
library('XML')
library('RSelenium')
library('wdman')
# КОНСТАНТЫ --------------------------------------------------------------------
#
## постоянная часть запроса данных (URL)
const.html <- c('http://zakupki.gov.ru/epz/contract/quicksearch/search.html?searchString',
'morphology',
'pageNumber',
'sortDirection',
'recordsPerPage',
'sortBy',
'fz44',
'priceFrom',
'priceTo',
'budgetLevels',
'budgetName',
'nonBudgetCodesList',
'placingWayForContractList_4',
'placingWayForContractList',
'contractStageList_1',
'contractStageList_2',
'contractStageList',
'regions',
'contractDateFrom',
'contractDateTo',
'contractInputNameDefenseOrderNumber',
'contractInputNameContractNumber',
'publishDateFrom',
'publishDateTo',
'updateDateFrom',
'updateDateTo')
## имя браузера для маскировки запроса по getURL()
userAgent <- 'Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko'
## имя файла для экспорта
exportCsvFileName <- paste0('zakupki_gov_ru_', Sys.time(), '.csv')
# ФУНКЦИИ ----------------------------------------------------------------------
#
#
# Применить xpath запрос и почистить возвращаемый результат
#  от хвостовых пробелов и спецсимволов
#
xpathApplyAndClean <- function(root.node, xpath.text, return.mode = 'value',
attr.name = NULL) {
# сами теги
if (return.mode == 'value') {
result <- xpathSApply(root.node, xpath.text, xmlValue)
}
if (return.mode == 'attr') {
result <- xpathSApply(root.node, xpath.text, xmlGetAttr, attr.name)
}
# убираем перевод каретки
result <- gsub(result, pattern = '\r\n', replacement = '')
# убираем пробелы по краям
result <- gsub(result, pattern = "^\\s+|\\s+$", replacement = '')
# возвращаем значения
return(result)
}
#
#
# Вместо try-catch для результатов xpath запроса:
#  если результат возвращается нулевой, меняем его на NA
tryXpath <- function(xpath.result) {
if (length(xpath.result) == 0) {
xpath.result <- NA
}
return(xpath.result)
}
# ПЕРЕМЕННЫЕ -------------------------------------------------------------------
#
## переменная часть запроса данных (URL)
var.html <- c('',                                       # searchString
'on',                                     # morphology
'1',                                      # pageNumber
'false',                                  # sortDirection
'_50',                                    # recordsPerPage
'PO_DATE_OBNOVLENIJA',                    # sortBy
'on',                                     # fz44
'0',                                      # priceFrom
'1000000',                                # priceTo
'',                                       # budgetLevels
'',                                       # budgetName
'',                                       # nonBudgetCodesList
'on',                                     # placingWayForContractList_4
'4',                                      # placingWayForContractList
'on',                                     # contractStageList_1
'on',                                     # contractStageList_2
'1%2C2',                                  # contractStageList
'',                                       # regions
'',                                       # contractDateFrom
'',                                       # contractDateTo
'',                                       # contractInputNameDefenseOrderNumber
'',                                       # contractInputNameContractNumber
'01.06.2017',                             # publishDateFrom
'31.08.2017',                             # publishDateTo
'',                                       # updateDateFrom
''                                        # updateDateTo
)
fileURL <- paste0(paste0(const.html, '=', var.html), collapse = '&')
# ЗАГРУЗКА ---------------------------------------------------------------------
#
## загружаем текст html-страницы
html <- getURL(fileURL, .encoding = 'UTF-8',
ssl.verifypeer = FALSE,
.opts = list(useragent = userAgent,
followlocation = TRUE))
## разбираем как html
doc <- htmlTreeParse(html, useInternalNodes = T)
## корневой элемент
rootNode <- xmlRoot(doc)
# ПАРСИНГ ----------------------------------------------------------------------
#
# РЕЕСТР КОНТРАКТОВ ============================================================
#
## настроечные переменные
#...............................................................................
### сколько страниц в выдаче
n.pages <- as.numeric(xpathApplyAndClean(rootNode,
"//div[@class = 'paginator greyBox']/ul/li"))
n.pages <- n.pages[!is.na(n.pages)]
rootNode
#
# В этом скрипте содержится код разбора выдачи сайта госзакупок zakupki.gov.ru
# Начало работы: 29.08.2017
# Автор: Светлана Аксюк (s.a.aksuk@gmail.com)
#
# Данные загружаются по запросу через URL.
# Пример URL для разбора:
# http://zakupki.gov.ru/epz/contract/quicksearch/search.html?searchString=&morphology=on&pageNumber=1&sortDirection=false&recordsPerPage=_50&sortBy=PO_DATE_OBNOVLENIJA&priceFrom=0&priceTo=1000000&budgetLevels=&budgetName=&nonBudgetCodesList=&placingWayForContractList_4=on&placingWayForContractList=4&contractStageList_1=on&contractStageList_2=on&contractStageList=1%2C2&regions=&contractDateFrom=&contractDateTo=&contractInputNameDefenseOrderNumber=&contractInputNameContractNumber=&publishDateFrom=01.01.2016&publishDateTo=29.08.2017&updateDateFrom=&updateDateTo=
#
# Результаты -- характеристики госзакупок из базы данных -- записыввются
#  в .csv файл.
# Ограничение API: 500 записей при выгрузке вручную с сайта.
# Мы запрашиваем все записи с максимальным количеством на странице: 50,
#  потом листаем в цикле. Внимание: заказы быстро добавляются, в конце
#  стоит проверить таблицу на наличие дубликатов. Уникальный идентификатор --
#  номер заказа (ContractID).
#
# ПАКЕТЫ -----------------------------------------------------------------------
#
library('RCurl')
library('XML')
library('RSelenium')
library('wdman')
# КОНСТАНТЫ --------------------------------------------------------------------
#
## постоянная часть запроса данных (URL)
const.html <- c('http://zakupki.gov.ru/epz/contract/quicksearch/search.html?searchString',
'morphology',
'pageNumber',
'sortDirection',
'recordsPerPage',
'sortBy',
'fz44',
'priceFrom',
'priceTo',
'budgetLevels',
'budgetName',
'nonBudgetCodesList',
'placingWayForContractList_4',
'placingWayForContractList',
'contractStageList_1',
'contractStageList_2',
'contractStageList',
'regions',
'contractDateFrom',
'contractDateTo',
'contractInputNameDefenseOrderNumber',
'contractInputNameContractNumber',
'publishDateFrom',
'publishDateTo',
'updateDateFrom',
'updateDateTo')
## имя браузера для маскировки запроса по getURL()
userAgent <- 'Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko'
## имя файла для экспорта
exportCsvFileName <- paste0('zakupki_gov_ru_', Sys.time(), '.csv')
# ФУНКЦИИ ----------------------------------------------------------------------
#
#
# Применить xpath запрос и почистить возвращаемый результат
#  от хвостовых пробелов и спецсимволов
#
xpathApplyAndClean <- function(root.node, xpath.text, return.mode = 'value',
attr.name = NULL) {
# сами теги
if (return.mode == 'value') {
result <- xpathSApply(root.node, xpath.text, xmlValue)
}
if (return.mode == 'attr') {
result <- xpathSApply(root.node, xpath.text, xmlGetAttr, attr.name)
}
# убираем перевод каретки
result <- gsub(result, pattern = '\r\n', replacement = '')
# убираем пробелы по краям
result <- gsub(result, pattern = "^\\s+|\\s+$", replacement = '')
# возвращаем значения
return(result)
}
#
#
# Вместо try-catch для результатов xpath запроса:
#  если результат возвращается нулевой, меняем его на NA
tryXpath <- function(xpath.result) {
if (length(xpath.result) == 0) {
xpath.result <- NA
}
return(xpath.result)
}
# ПЕРЕМЕННЫЕ -------------------------------------------------------------------
#
## переменная часть запроса данных (URL)
var.html <- c('',                                       # searchString
'on',                                     # morphology
'1',                                      # pageNumber
'false',                                  # sortDirection
'_50',                                    # recordsPerPage
'PO_DATE_OBNOVLENIJA',                    # sortBy
'on',                                     # fz44
'0',                                      # priceFrom
'1000000',                                # priceTo
'',                                       # budgetLevels
'',                                       # budgetName
'',                                       # nonBudgetCodesList
'on',                                     # placingWayForContractList_4
'4',                                      # placingWayForContractList
'on',                                     # contractStageList_1
'on',                                     # contractStageList_2
'1%2C2',                                  # contractStageList
'',                                       # regions
'',                                       # contractDateFrom
'',                                       # contractDateTo
'',                                       # contractInputNameDefenseOrderNumber
'',                                       # contractInputNameContractNumber
'01.06.2017',                             # publishDateFrom
'31.08.2017',                             # publishDateTo
'',                                       # updateDateFrom
''                                        # updateDateTo
)
fileURL <- paste0(paste0(const.html, '=', var.html), collapse = '&')
# ЗАГРУЗКА ---------------------------------------------------------------------
#
## загружаем текст html-страницы
html <- getURL(fileURL, .encoding = 'UTF-8',
ssl.verifypeer = FALSE,
.opts = list(useragent = userAgent,
followlocation = TRUE))
## разбираем как html
doc <- htmlTreeParse(html, useInternalNodes = T)
## корневой элемент
rootNode <- xmlRoot(doc)
rootNode
fileURL
url <- 'ftp://ftp.zakupki.gov.ru/'
userpwd <- 'free:free'
filenames <- getURL(url, userpwd = userpwd,
ftp.use.epsv = FALSE, dirlistonly = TRUE)
library('RCurl')
url <- 'ftp://ftp.zakupki.gov.ru/'
userpwd <- 'free:free'
filenames <- getURL(url, userpwd = userpwd,
ftp.use.epsv = FALSE, dirlistonly = TRUE)
dir()
?dir
dir('fcs_regions/Moskovskaja_obl/contracts/')
url <- 'fcs_regions/Moskovskaja_obl/contracts/';
zips <- system(paste0('lftp ',url,' <<<\'find| grep "\\\\.zip$"; exit;\';'),intern = T);
dir('ftp://ftp.zakupki.gov.ru/fcs_regions/Moskovskaja_obl/contracts/')
getURL(url, ftp.use.epsv = FALSE, dirlistonly = TRUE)
url <- 'ftp://ftp.zakupki.gov.ru/'
getURL(url, ftp.use.epsv = FALSE, dirlistonly = TRUE)
getURL('ftp://ftp.zakupki.gov.ru/fcs_regions/Moskovskaja_obl/',
ftp.use.epsv = FALSE, dirlistonly = TRUE)
getURL('ftp://ftp.zakupki.gov.ru/fcs_regions/Moskovskaja_obl/',
ftp.use.epsv = FALSE, dirlistonly = TRUE,
.encoding = 'UTF-8',
ssl.verifypeer = FALSE,
.opts = list(useragent = userAgent,
followlocation = TRUE))
userAgent <- 'Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko'
exportCsvFileName <- paste0('zakupki_gov_ru_', Sys.time(), '.csv')
getURL('ftp://ftp.zakupki.gov.ru/fcs_regions/Moskovskaja_obl/',
ftp.use.epsv = FALSE, dirlistonly = TRUE,
.encoding = 'UTF-8',
ssl.verifypeer = FALSE,
.opts = list(useragent = userAgent,
followlocation = TRUE))
getURL('ftp://ftp.zakupki.gov.ru/fcs_regions/Moskovskaja_obl/',
ftp.use.epsv = FALSE, dirlistonly = TRUE, userpwd = userpwd)
strsplit(getURL('ftp://ftp.zakupki.gov.ru/fcs_regions/Moskovskaja_obl/',
ftp.use.epsv = FALSE, dirlistonly = TRUE, userpwd = userpwd),
'\r\n')
strsplit(getURL('ftp://ftp.zakupki.gov.ru/fcs_regions/Moskovskaja_obl/contracts',
ftp.use.epsv = FALSE, dirlistonly = TRUE, userpwd = userpwd),
'\r\n')
strsplit(getURL('ftp://ftp.zakupki.gov.ru/fcs_regions/Moskovskaja_obl/contracts.',
ftp.use.epsv = FALSE, dirlistonly = TRUE, userpwd = userpwd),
'\r\n')
strsplit(getURL('ftp://ftp.zakupki.gov.ru/fcs_regions/Moskovskaja_obl/contracts/',
ftp.use.epsv = FALSE, dirlistonly = TRUE, userpwd = userpwd),
'\r\n')
zips <- strsplit(getURL('ftp://ftp.zakupki.gov.ru/fcs_regions/Moskovskaja_obl/contracts/',
ftp.use.epsv = FALSE, dirlistonly = TRUE, userpwd = userpwd),
'\r\n')
grep('[_2016]|[_2017]', zips)
grepl('[_2016]|[_2017]', zips)
zips
zips[grepl('[_2016]|[_2017]', zips)]
grepl('[_2016]|[_2017]', zips)
zips[grepl(pattern = '[_2016]|[_2017]', zips)]
zips[grepl(pattern = '_201609', zips)]
length(zips)
zips
length(zips)
dim(zips)
nrow(zips)
nchar(zips)
tail(zips)
?strsplit
is.list(zip())
is.list(zips
)
region.folder.url <- 'ftp://ftp.zakupki.gov.ru/fcs_regions/Moskovskaja_obl/contracts/'
zips <- unlist(strsplit(getURL(region.folder.url,  ftp.use.epsv = FALSE,
dirlistonly = TRUE, userpwd = userpwd),
'\r\n'))
lehgth(zips)
length(zips)
url <- 'ftp://ftp.zakupki.gov.ru/'
userpwd <- 'free:free'
# список директорий в папке
strsplit(getURL(paste0(url, 'fcs_regions/Moskovskaja_obl/'),
ftp.use.epsv = FALSE, dirlistonly = TRUE, userpwd = userpwd),
'\r\n')
# список файлов в папке
strsplit(getURL(paste0(url, 'fcs_regions/Moskovskaja_obl/contracts/'),
ftp.use.epsv = FALSE, dirlistonly = TRUE, userpwd = userpwd),
'\r\n')
# выбираем только 2017 и 2016 гг
region.folder.url <- 'ftp://ftp.zakupki.gov.ru/fcs_regions/Moskovskaja_obl/contracts/'
zips <- unlist(strsplit(getURL(region.folder.url,  ftp.use.epsv = FALSE,
dirlistonly = TRUE, userpwd = userpwd),
'\r\n'))
length(zips)
zips[1]
zips[1]
strsplit(getURL(paste0(url, 'fcs_regions/'),
ftp.use.epsv = FALSE, dirlistonly = TRUE, userpwd = userpwd),
'\r\n')
region.folders.names <- strsplit(getURL(paste0(url, 'fcs_regions/'),
ftp.use.epsv = FALSE,
dirlistonly = TRUE,
userpwd = userpwd),
'\r\n')
gsub('_obl$', region.folders.names)
grep('_obl$', region.folders.names)
grep('_obl^', region.folders.names)
?grep
grep('_obl', region.folders.names)
region.folders.names <- unlist(strsplit(getURL(paste0(url, 'fcs_regions/'),
ftp.use.epsv = FALSE,
dirlistonly = TRUE,
userpwd = userpwd),
'\r\n'))
grep('_obl', region.folders.names)
grep('_obl$', region.folders.names)
region.folders.names[grep('_obl$', region.folders.names)]
region.folders.names[grep('[_obl]|[_Resp]$', region.folders.names)]
region.folders.names[grep('[_obl$]|[_Resp$]', region.folders.names)]
region.folders.names[grep('[_obl]|[_Resp]$', region.folders.names)]
region.folders.names[grep('_obl|_Resp$', region.folders.names)]
region.folders.names[grep('_Resp$', region.folders.names)]
region.folders.names[grep('_obl$', region.folders.names)]
region.folders.names[grep('_kraj$', region.folders.names)]
region.folders.names[grep('_.obl$', region.folders.names)]
region.folders.names[grep('_[.|]obl$', region.folders.names)]
region.folders.names[grep('_.+obl$', region.folders.names)]
region.folders.names[grep('_{.,0}obl$', region.folders.names)]
region.folders.names[grep('_.?obl$', region.folders.names)]
region.folders.names[grep('_Resp$|_kraj$', region.folders.names)]
region.folders.names[grep('_Resp$|_kraj$|_.?obl$', region.folders.names)]
length(region.folders.names[grep('_Resp$|_kraj$|_.?obl$', region.folders.names)])
region.folders.names <- region.folders.names[grep('_Resp$|_kraj$|_.?obl$',
region.folders.names)]
length(region.folders.names)
region.folder.url <- paste0(region.folders.names, '/contracts/')
region.folder.url
region.folder.url <- paste0('ftp://ftp.zakupki.gov.ru/fcs_regions/',
region.folders.names, '/contracts/')
region.folder.url
region.folder.url
region.folders.names
m
df.summary.contracts <- data.frame(region = region.folders.names,
number_of_contracts_2017 = 0)
df.summary.contracts
